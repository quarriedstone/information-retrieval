{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [40] Language and Topic models\n",
    "\n",
    "A common suggestion to users for coming up with good queries is to think of words that would likely appear in a relevant document, and to use those words as the query. The language modeling approach to IR directly models this idea: a document is a good match to a query if the document model is likely to generate the query, which will in turn happen if the document contains the query words often. \n",
    "\n",
    "You will score documents with respect to user query using language models and also get some experience with topic modelling.\n",
    "\n",
    "## 1.0. [5] Loading data\n",
    "\n",
    "We use the dataset we already used once - [this topic-modeling dataset](https://code.google.com/archive/p/topic-modeling-tool/downloads) ([or from github](https://github.com/IUCVLab/information-retrieval/blob/main/datasets/topic-modelling.zip))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents 15002\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "# TODO: read the dataset\n",
    "path = \"../datasets/topic-modelling/\"\n",
    "_, _, filenames = next(os.walk(path))\n",
    "\n",
    "labels = {\n",
    "    \"testdata_braininjury_10000docs.txt\" : \"brain_injury\",\n",
    "    \"testdata_news_music_2084docs.txt\"   : \"music\",\n",
    "    \"testdata_news_fuel_845docs.txt\"     : \"fuel\",\n",
    "    \"testdata_news_economy_2073docs.txt\" : \"news_economy\"\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "for filename in filenames:\n",
    "    with open(path + filename, \"r\") as f:\n",
    "        sentences = f.read().split(\"\\n\")\n",
    "        all_data.extend([(word_tokenize(sentence.lower()), labels[filename], doc_id) for doc_id, sentence in enumerate(sentences) if sentence])\n",
    "\n",
    "\n",
    "print(\"# of documents\", len(all_data))\n",
    "assert len(all_data) == 15002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. [35] Ranking Using Language Models\n",
    "Our goal is to rank documents by $P(d|q)$, where the probability of a document is interpreted as the likelihood that it is relevant to the query. \n",
    "\n",
    "Using Bayes rule: $P(d|q) = \\frac{P(q|d)P(d)}{P(q)}$\n",
    "\n",
    "$P(q)$ is the same for all documents, and so can be ignored. The prior probability of a document $P(d)$ is often treated as uniform across all $d$'s and so it can also be ignored. What does it mean? \n",
    "\n",
    "It means that computing $P(q|d)$ for different documents we can compare how relevant are they to the query. How can we estimate $P(q|d)$?\n",
    "\n",
    "$P(q|d)$ can be estimated as:\n",
    "\n",
    "![](https://i.imgur.com/BEIMAC1.png)\n",
    "\n",
    "where $M_d$ is the language model of document $d$, $tf_{t,d}$ is the term frequency of term $t$ in document $d$, and $L_d$ is the number of tokens in document $d$. That is, we just count up how often each word occurred, and divide by the total number of words in the document $d$.\n",
    "\n",
    "### 1.1.1. [5] Build TDM (or DTM)\n",
    "\n",
    "The first thing we need to do is to build a term-document matrix for tour dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build term-document matrix for the dataset\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "TDM = defaultdict(Counter)\n",
    "doc_to_label = {}\n",
    "doc_to_doc = {}\n",
    "for sentence, label, doc_id in all_data:\n",
    "    TDM[doc_id].update(Counter(sentence))\n",
    "    doc_to_label[doc_id] = label\n",
    "    doc_to_doc[doc_id] = sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. [15] Smoothing\n",
    "\n",
    "Now, you need to implement the abovementioned logic in the `lm_rank_documents` function below. Do you see any potential problems?\n",
    "\n",
    "Yes, data sparsity - we don't expect to meet each term in each doc, so, in most cases, we will get zero scores, which is not what we really want.\n",
    "\n",
    "The solution is smooting.\n",
    "\n",
    "One option is *[additive smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)* - adding a small number (0 to 1) to the observed counts and renormalizing to give a probability distribution.\n",
    "\n",
    "Another option is called [Jelinek-Mercer smoothing](http://mlwiki.org/index.php/Smoothing_for_Language_Models#Jelinek-Mercer_Smoothing) - a simple idea that works well in practice is to use a mixture between a document-specific distribution and distribution estimated from the entire collection:\n",
    "\n",
    "![](https://i.imgur.com/8Qv41Wp.png)\n",
    "\n",
    "where 0 < Î» < 1 and $M_c$ is a language model built from the entire document collection.\n",
    "\n",
    "Refer to [*Chapter 12*](https://nlp.stanford.edu/IR-book/html/htmledition/language-models-for-information-retrieval-1.html) for the detailed explanation.\n",
    "\n",
    "\n",
    "You are going to apply both in your `lm_rank_documents` function. This function takes TDM or DTM as an input, and ranks all documents \"building\" a language model for each document, returning relative probabilities of query being generated by a document as a document's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lm_rank_documents(query, tdm, smoothing='additive', param=0.001):\n",
    "    # TODO: score each document in tdm using this document's language model\n",
    "    # implement two types of smoothing. Looks up term frequencies in tdm\n",
    "    # return document scores in a convenient form\n",
    "    # param is alpha for additive / lambda for jelinek-mercer\n",
    "    \n",
    "    scores = defaultdict(lambda: 1.0)\n",
    "    \n",
    "    TDM_entire = Counter()\n",
    "    for doc_counter in TDM.values():\n",
    "        TDM_entire.update(doc_counter)\n",
    "    \n",
    "    if smoothing == 'additive':\n",
    "        d = len(TDM_entire.keys())\n",
    "        for doc_id, words_freq in TDM.items():\n",
    "            doc_length = sum(words_freq.values())\n",
    "            for word in query:\n",
    "                scores[doc_id]*=(words_freq[word] + param)/(doc_length + param*d)\n",
    "    \n",
    "    if smoothing == \"jelinek\":    \n",
    "        for doc_id, words_freq in TDM.items():\n",
    "            doc_length = sum(words_freq.values())\n",
    "            entire_length = sum(TDM_entire.values())\n",
    "            pMd = 1\n",
    "            pMc = 1\n",
    "            for word in query:\n",
    "                pMd*=words_freq[word]/doc_length\n",
    "                pMc*=TDM_entire[word]/entire_length\n",
    "                \n",
    "            scores[doc_id] = (1-param)*pMd + param*pMc\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. [15] Testing\n",
    "\n",
    "Check if this type of ranking gives meaningful results. For each query output document `category`, `doc_id`, `score`, and the *beginning* of the document, as it is shown below. Analyze if categories and contents match the queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query: piano concert\n",
      "\n",
      "search top-5 results:\n",
      "news_economy 890 8.984497535964978e-06\n",
      "the budget that president bush will send congress week from monday strays far  ...\n",
      "news_economy 916 8.969391519224745e-06\n",
      "president bush vowed rally the nation with wartime state the union address tuesday  ...\n",
      "news_economy 670 3.049589815902634e-06\n",
      "amp princess cruises rejected sweetened bid monday from the carnival corp the world  ...\n",
      "news_economy 1782 2.041838678712098e-06\n",
      "jayson williams the former new jersey nets basketball star turned himself the new  ...\n",
      "news_economy 1994 1.8821552941897665e-06\n",
      "chrysler said monday that planned make convertible version the cruiser which was instant  ...\n",
      "\n",
      "\n",
      "user query: symptoms of head trauma\n",
      "\n",
      "search top-5 results:\n",
      "brain_injury 9355 2.660886418304183e-11\n",
      "incidental finding chiari malformation with progression symptoms after head trauma case report chiari  ...\n",
      "brain_injury 6279 2.4186974341385217e-11\n",
      "head trauma female professional wrestlers the clinical characteristics head trauma were evaluated wrestlers  ...\n",
      "brain_injury 5023 1.8114526519144027e-11\n",
      "utility computed tomography the head following head trauma boys with haemophilia the most  ...\n",
      "brain_injury 7351 1.7676233371621466e-11\n",
      "functional time limit and onset symptoms infant abusive head trauma aim analyse medical  ...\n",
      "brain_injury 2679 8.812081850159878e-12\n",
      "misleading anisocoria comatose year old with head injury anisocoria after blunt head trauma  ...\n",
      "\n",
      "\n",
      "user query: wall street journal\n",
      "\n",
      "search top-5 results:\n",
      "news_economy 1587 2.746649885053012e-08\n",
      "terrorism fades nation most important problem said the headline analysis the gallup news  ...\n",
      "news_economy 1588 2.5762813377538672e-08\n",
      "the university massachusetts deja all over again the state another budget crisis and  ...\n",
      "news_economy 908 1.539455729281765e-08\n",
      "enron enron enron like jan brady plaintive cry the attention older sister marcia  ...\n",
      "news_economy 448 1.2185446679673944e-08\n",
      "for questions please call enron enron main washington the powerful senate banking committee  ...\n",
      "news_economy 845 8.458753804020084e-09\n",
      "saw this week that president bush outraged the enron scandal and know should  ...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_query(raw_query):\n",
    "    # TODO: process user query and print search results including document category, id, score, and some part of it\n",
    "    query_words = word_tokenize(raw_query.lower())\n",
    "    results = lm_rank_documents(query_words, TDM, smoothing='additive', param=0.001)\n",
    "    sorted_res = sorted(list(results.items()), key=lambda x: x[1], reverse=True)\n",
    "    print(\"user query: \" + raw_query + \"\\n\")\n",
    "    print(\"search top-5 results:\")\n",
    "    for doc_id, score in sorted_res[:5]:\n",
    "        print(doc_to_label[doc_id], doc_id, score)\n",
    "        print(\" \".join(doc_to_doc[doc_id][:13]), \" ...\")\n",
    "    \n",
    "\n",
    "user_queries = [\"piano concert\", \"symptoms of head trauma\", \"wall street journal\"]\n",
    "for q in user_queries:\n",
    "    process_query(q)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample results can look like this (if collapsed, click on 3 dots):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "user query: piano concert\n",
    "\n",
    "search results:\n",
    "music 13330 0.012384164490679759\n",
    "atlanta prominent midtown intersection one step closer becoming major cultural landmark the atlanta ...\n",
    "economy 11335 0.012384164490679759\n",
    "atlanta prominent midtown intersection one step closer becoming major cultural landmark the atlanta ...\n",
    "music 12926 0.011382499792705511\n",
    "felt like was going church marry guy never met said the jazz violinist regina carter the metaphorica...\n",
    "music 14390 0.010661589922122\n",
    "hailed los angeles brightest flower its flashiest ship sail its keenest architectural triumph perhap...\n",
    "music 13818 0.010549141787975117\n",
    "everything was finished sept the super bowl logo would reflection new orleans featuring streetcar an...\n",
    "\n",
    "\n",
    "user query: symptoms of head trauma\n",
    "\n",
    "search results:\n",
    "brain_injury 7319 0.06022877378376099\n",
    "the direct economic burden blunt and penetrating trauma managed care population background although ...\n",
    "brain_injury 6987 0.05854539395767944\n",
    "history reported head trauma sample women substance abuse treatment objectives determine the prevale...\n",
    "brain_injury 5257 0.05760140208255336\n",
    "violent head trauma china report cases background the occurrence violent trauma has recently increas...\n",
    "brain_injury 1536 0.055365767080148634\n",
    "mild head trauma and chronic headaches returning soldiers objective determine the incidence and type...\n",
    "brain_injury 8874 0.05379997937839304\n",
    "maxillofacial trauma major trauma patients background trauma has been identified major public health...\n",
    "\n",
    "\n",
    "user query: wall street journal\n",
    "\n",
    "search results:\n",
    "economy 11294 0.027288833622119528\n",
    "these business stories for release tuesday january are moving today clients the new york times news ...\n",
    "economy 11295 0.027288833622119528\n",
    "these business stories for release tuesday january are moving today clients the new york times news ...\n",
    "music 14641 0.026716049665405375\n",
    "these feature stories are moving today clients the new york times news service stories are for relea...\n",
    "music 14640 0.026716049665405375\n",
    "these feature stories are moving today clients the new york times news service stories are for relea...\n",
    "economy 11297 0.025763725974814314\n",
    "these feature stories are moving today clients the new york times news service stories are for relea...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. [+10/100] Bonus - topic modeling\n",
    "\n",
    "Now let's use *Latent Dirichlet Allocation* to identify topics in this collection and check if they match the original topics (fuel, economy, etc.). Go through the tutorial [here](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0) and apply the ideas there to our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: apply LDA to our dataset and output the resulting categories \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect to see something like this (if collapsed, click on 3 dots):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "Topic #0:\n",
    "brain injury patients tbi traumatic study cerebral results severe group cognitive clinical pressure imaging following outcome control using children test\n",
    "\n",
    "Topic #1:\n",
    "new said york news atlanta like times year service time people undated just music journal constitution city says com years\n",
    "\n",
    "Topic #2:\n",
    "patients injury injuries trauma head study results traumatic brain treatment cases patient fractures years case outcome methods clinical tbi surgery\n",
    "\n",
    "Topic #3:\n",
    "said year bush percent new enron company president government people economy years million state companies states economic united time billion\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. [60] Sugges_\n",
    "\n",
    "One of the strategies to improve user experience is to provide user with hints, or, otherwise, to autocomplete his queries. Let's consider suggest.\n",
    "\n",
    "Today we will practice generating suggestions using [Trie](https://en.wikipedia.org/wiki/Trie) datastructure (prefix tree), see the example below.\n",
    "\n",
    "Plan of your homework:\n",
    "\n",
    "1. Build Trie based on real search query data, provided by AOL company;\n",
    "2. Generate suggestion based on trie;\n",
    "3. Measure suggestion speed;\n",
    "4. (+) Optionally add spellcheck to suggest.\n",
    "\n",
    "\n",
    "![image](https://www.ritambhara.in/wp-content/uploads/2017/05/Screen-Shot-2017-05-01-at-4.01.38-PM.png)\n",
    "\n",
    "## 2.0. Install Trie data structure support\n",
    "\n",
    "You are free to use any library implementation of Trie, as well as the one we suggest (read the docs before asking any questions!): https://github.com/google/pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygtrie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1. Check it works and understand the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharTrie(this is 1: A, this is 2: B, that is 3: C)\n",
      "Node = False\n",
      "Subtree = True\n",
      "this is 1 ~ A\n",
      "this is 2 ~ B\n"
     ]
    }
   ],
   "source": [
    "import pygtrie\n",
    "t = pygtrie.CharTrie()\n",
    "\n",
    "# trie can be considered as a form of organizing a set of map\n",
    "t[\"this is 1\"] = \"A\"\n",
    "t[\"this is 2\"] = \"B\"\n",
    "t[\"that is 3\"] = \"C\"\n",
    "\n",
    "print(t)\n",
    "\n",
    "# \"this\" string is present in a set\n",
    "n = t.has_node('this') == pygtrie.Trie.HAS_VALUE\n",
    "# \"this\" prefix is present in a set\n",
    "s = t.has_node('this') == pygtrie.Trie.HAS_SUBTRIE\n",
    "\n",
    "print(f\"Node = {n}\\nSubtree = {s}\")\n",
    "\n",
    "# iterate a subtree\n",
    "for key, val in t.iteritems(\"this\"):\n",
    "    print(key, '~', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Build a trie upon a dataset\n",
    "\n",
    "### 2.1.1. [5] Read dataset\n",
    "\n",
    "Download the [dataset](https://github.com/IUCVLab/information-retrieval/tree/main/datasets/aol) (we provide only the first part of the original data for simplicity (~3.5 mln queries)).\n",
    "\n",
    "Explore the data, see readme file. Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "aol_data = pd.read_csv(\"../datasets/aol/user-ct-test-collection-01.txt\", encoding='utf-8', sep=\"\\t\")\n",
    "\n",
    "#TODO: Read the dataset, e.g. as pandas dataframe\n",
    "\n",
    "assert aol_data.shape[0] == 3558411, \"Dataset size doesnt' match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. [20] Build Trie\n",
    "\n",
    "We want suggest function to be **non-sensitive to stop words** because we don't want to upset the user if he confuses/omits prepositions, for example. Consider *\"public events in Innopolis\"* vs *\"public events at Innopolis\"* or *\"public events Innopolis\"* - they all mean the same.\n",
    "\n",
    "Build Trie based on the dataset, **storing query statistics such as query frequency, urls and ranks in nodes**. Some queries may not have associated urls, others may have multiple ranked urls. Think of the way to store this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870dbb5d2f1245d782551ae17b9f595f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3558411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "term_count = Counter()\n",
    "query_to_urls_ranks = defaultdict(list)\n",
    "\n",
    "term_number = len(aol_data)\n",
    "\n",
    "for _, row in tqdm(aol_data.iterrows(), total=term_number):\n",
    "    query = row.Query\n",
    "    term_count.update([str(query)])\n",
    "    query_to_urls_ranks[query].append((row.ClickURL, row.ItemRank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/osmiyg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7534d4e8407342e9abaab5a663097a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1216653.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, download\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "download('stopwords')\n",
    "\n",
    "#TODO: build trie based on dataset\n",
    "aol_trie = pygtrie.CharTrie()\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "for query, query_count in tqdm(term_count.items()):\n",
    "    cleaned_query = \" \".join([word for word in query.split(\" \") if word not in stop_words])\n",
    "    cleaned_urls = [pair for pair in query_to_urls_ranks[query] if not math.isnan(pair[1])]\n",
    "    aol_trie[cleaned_query] = (query_count/term_number, cleaned_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample question surveys ~ (1.4051215556606586e-06, [('http://www.surveyconnect.com', 7.0), ('http://www.custominsight.com', 4.0), ('http://www.askemployees.com', 10.0), ('http://www.lg-employers.gov.uk', 1.0)])\n",
      "sample questions immigration interview ~ (2.810243111321317e-07, [])\n",
      "sample questions interview ~ (2.810243111321317e-07, [('http://www.quintcareers.com', 1.0)])\n",
      "sample questions family interview ~ (8.430729333963952e-07, [('http://www.grandparents-day.com', 2.0), ('http://www.quintcareers.com', 5.0), ('http://jobsearchtech.about.com', 3.0)])\n",
      "sample questions sociology race ethnicity ~ (2.810243111321317e-07, [])\n",
      "sample questions biology ~ (5.620486222642634e-07, [('http://www.utexas.edu', 3.0), ('http://www.troy.k12.ny.us', 6.0)])\n",
      "sample questions us citizenship test ~ (2.810243111321317e-07, [('http://uscis.gov', 1.0)])\n",
      "sample questionarie teaching evaluation ~ (2.810243111321317e-07, [])\n",
      "sample questionnaire teaching evaluation ~ (1.4051215556606586e-06, [('http://www.surveyconsole.com', 1.0), ('http://www.usask.ca', 2.0), ('http://teaching.berkeley.edu', 6.0), ('http://www.flinders.edu.au', 9.0), ('http://oregonstate.edu', 10.0)])\n",
      "sample questionnaire clinical research coordinators certification ~ (2.810243111321317e-07, [('http://www.pharmatech.com', 9.0)])\n"
     ]
    }
   ],
   "source": [
    "# test trie\n",
    "bag = []\n",
    "for key, val in aol_trie.iteritems(\"sample q\"):\n",
    "    print(key, '~', val)\n",
    "    \n",
    "    #NB: here we assume you store urls in a list field. But you can do something different.\n",
    "    bag += [url for url, _ in val[1]]\n",
    "    \n",
    "    assert \"sample question\" in key, \"All examples have `sample question` substring\"\n",
    "    assert key[:len(\"sample question\")] == \"sample question\", \"All examples have `sample question` starting string\"\n",
    "\n",
    "for url in [\"http://www.surveyconnect.com\", \"http://www.custominsight.com\", \n",
    "            \"http://jobsearchtech.about.com\", \"http://www.troy.k12.ny.us\",\n",
    "            \"http://www.flinders.edu.au\", \"http://uscis.gov\"]:\n",
    "    assert url in bag, \"This url should be in a try\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. [20] Write a suggest function which is non-sensitive to stop words\n",
    "\n",
    "Suggest options for user query based on Trie you just built.\n",
    "Output results sorted by frequency, print query count for each suggestion. If there is an url available, print the url too. If multiple url-s are available, print the one with the highest rank (the less the better).\n",
    "\n",
    "Q: What is the empirical threshold for minimal prefix for suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: trie\n",
      "Results:\n",
      "('tried true tattoo', 'http://www.triedntruetattoo.com')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-1db7601b0605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#NB we assume you return suggested query string only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tried and true tattoo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"triest\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"triethanalomine\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def complete_user_query(query, trie, top_k=5):\n",
    "    #TODO: suggest top_k options for a user query\n",
    "    # sort results by frequency, suggest first ranked urls if available\n",
    "    cleaned_query = \" \".join([word for word in query.split() if word not in stop_words])\n",
    "    top_k_results = sorted(aol_trie.iteritems(query), key=lambda x: x[1][0], reverse=True)[:top_k]\n",
    "    all_urls = []\n",
    "    for _, url in top_k_results:\n",
    "        all_urls.extend(url[1])\n",
    "    \n",
    "    if all_urls:\n",
    "        best = sorted(all_urls, key=lambda x: x[1])[0][0]\n",
    "    \n",
    "    return (top_k_results[0][0], best)\n",
    "        \n",
    "inp = \"trie\"\n",
    "print(\"Query:\", inp)\n",
    "res = complete_user_query(inp, aol_trie)\n",
    "\n",
    "#NB we assume you return suggested query string only\n",
    "\n",
    "## NO AND HERE\n",
    "assert res[0] == \"tried and true tattoo\"\n",
    "assert res[1] == \"triest\" or res[1] == \"triethanalomine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. [15] Measure suggest speed ##\n",
    "\n",
    "Check how fast your search is working. Consider changing your code if it takes too long on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('information clearing house', 'http://www.informationclearinghouse.info')\n",
      "Query inf : 0.022538000000167813\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'the best '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-5ba34c6fa2d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minp_queries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcomplete_user_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maol_trie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Query \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-191-1db7601b0605>\u001b[0m in \u001b[0;36mcomplete_user_query\u001b[0;34m(query, trie, top_k)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# sort results by frequency, suggest first ranked urls if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcleaned_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtop_k_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maol_trie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mall_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_k_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/pygtrie.py\u001b[0m in \u001b[0;36miteritems\u001b[0;34m(self, prefix, shallow)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0many\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \"\"\"\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         for path, value in node.iterate(list(self.__path_from_key(prefix)),\n\u001b[1;32m    635\u001b[0m                                         shallow, self._iteritems):\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/pygtrie.py\u001b[0m in \u001b[0;36m_get_node\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m             \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the best '"
     ]
    }
   ],
   "source": [
    "from time import process_time \n",
    "inp_queries = [\"inf\", \"the best \", \"information retrieval\", \"sherlock hol\", \"carnegie mell\", \n",
    "               \"babies r\", \"new york\", \"googol\", \"inter\", \"USA sta\", \"Barbara \"]\n",
    "start_all = process_time()\n",
    "for query in inp_queries:\n",
    "    start = process_time()\n",
    "    complete_user_query(query, aol_trie)\n",
    "    print(\"Query \" + query + \" : \" + str(process_time() - start))\n",
    "\n",
    "print(\"Overral time: \" + (start_all - process_time))\n",
    "\n",
    "#TODO: measure avg execution time (in milliseconds) per query and print it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. [+10/100] Bonus task - add spellchecking to your suggest\n",
    "\n",
    "Try to make your search results as close as possible. Compare top-5 results of each query with top-5 results for corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-194-05f58dd0c578>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-194-05f58dd0c578>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    spell.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "inp_queries = [\"inormation retrieval\", \"shelrock hol\", \"carnagie mell\", \"babis r\", \"Barrbara \"]\n",
    "inp_queries_corrected = [\"information retrieval\", \"sherlock hol\", \"carnegie mell\", \"babies r\", \"Barbara \"]\n",
    "\n",
    "\n",
    "def complete_user_query_with_spellchecker(query, trie, top_k=5):\n",
    "    #TODO: suggest top_k options for a user query\n",
    "    # sort results by frequency, suggest first ranked urls if available\n",
    "    def spellss(s):\n",
    "        ws = s.split()\n",
    "        cs = [list(spell.candidates(w)) for w in ws]\n",
    "        return rec(cs)\n",
    "\n",
    "    spell = SpellChecker()\n",
    "    cleaned_query = \" \".join([word for word in query.split() if word not in stop_words])\n",
    "\n",
    "\n",
    "for q, qc in zip(inp_queries, inp_queries_corrected):\n",
    "    assert  complete_user_query(qc, trie, 5) == \\\n",
    "            complete_user_query_with_spellchecker(q, trie, 5), \"Assert {} and {} give different results\".format(q, qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
