{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Authentication in a service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. What do you store in your Google Drive?\n",
    "\n",
    "Sometimes it can be quite troublesome to crawl web data - for example, when you can't just collect data from web-pages because the authentification to a website is required. Today's tutorial is about a dataset of special type - namely, Google Drive data. You will need to get access to the system using OAuth protocol, download and parse files of different types.\n",
    "\n",
    "Plan. \n",
    "1. Download [this little archive](https://drive.google.com/open?id=1Xji4A_dEAm_ycnO0Eq6vxj7ThcqZyJZR), **unzip** it and place the folder anywhere inside your Google Drive. You should get a subtree of 6 folders with files of different types: presentations, pdf-files, texts, and even code.\n",
    "2. Go to [Google Drive API](https://developers.google.com/drive/api/v3/quickstart/python) documentation, read [intro](https://developers.google.com/drive/api/v3/about-sdk) and learn how to [search for files](https://developers.google.com/drive/api/v3/reference/files/list) and [download](https://developers.google.com/drive/api/v3/manage-downloads) them. Pay attention, that  working at `localhost` (jupyter) and at `google colab` can be slighty different. We expect you to run from localhost.\n",
    "3. Learn how to open from python such files as [pptx](https://python-pptx.readthedocs.io/en/latest/user/quickstart.html), pdf, docx or even use generalized libraries like [textract](https://textract.readthedocs.io/en/stable/index.html), save internal text in a file near.\n",
    "4. Write a code with returns names (with paths) of files for a given substring. Test on these queries.\n",
    "```\n",
    "segmentation\n",
    "algorithm\n",
    "classifer\n",
    "printf\n",
    "predecessor\n",
    "Шеннон\n",
    "Huffman\n",
    "function\n",
    "constructor\n",
    "machine learning\n",
    "dataset\n",
    "Протасов\n",
    "Protasov\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Access GDrive ###\n",
    "\n",
    "Below is the example of how you can oranize your code - it's fine if you change it.\n",
    "\n",
    "Let's extract the list of all files that are contained (recursively) in t\n",
    "he folder of interest. In my case, I called it `air_oauth_folder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install some dependencies\n",
    "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdrive_get_all_files_in_folder(folder_name):\n",
    "    #TODO retrieve all files from a given folder   \n",
    "    return []\n",
    "\n",
    "def gdrive_download_file(file, path_to_save): \n",
    "    #TODO download file and save it under the path\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_of_interest = 'air_oauth_folder'\n",
    "files = gdrive_get_all_files_in_folder(folder_of_interest)\n",
    "\n",
    "test_dir = \"test_files\"\n",
    "for item in files:\n",
    "    gdrive_download_file(item, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Tests ###\n",
    "Please fill free to change function signatures and behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(files) == 34, 'Number of files is incorrect'\n",
    "print('n_files:', len(files))\n",
    "\n",
    "print(\"file here means id and name, e.g.: \", files[0])\n",
    "\n",
    "gdrive_download_file(files[0], '.')\n",
    "\n",
    "import os.path\n",
    "assert os.path.isfile(os.path.join('.', files[0][1])), \"File is not downloaded correctly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Read files content\n",
    "### 1.2.1. Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install textract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For windows please refer to \n",
    "- https://textract.readthedocs.io/en/latest/installation.html#don-t-see-your-operating-system-installation-instructions-here\n",
    "\n",
    "- https://www.xpdfreader.com/download.html\n",
    "\n",
    "ALSO BE CAREFUL WITH SPACES IN NAMES. Better save without spaces!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract \n",
    "\n",
    "def get_file_strings(path):\n",
    "    #TODO change this function to handle different data types properly \n",
    "    # - textract is not able to parse everything\n",
    "    # Take care of non-text data too\n",
    "    texts = str(textract.process(path)).replace('\\\\n', '\\n').replace('\\\\r', '').split('\\n')\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary of parsed files\n",
    "files_data = dict()\n",
    "for file in os.scandir(test_dir):    \n",
    "    strings = get_file_strings(file.path)\n",
    "    if strings:\n",
    "        files_data[file.name] = strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Tests for read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(files_data) == 31 \n",
    "print(len(files_data))\n",
    "\n",
    "assert \"Protasov\" in get_file_strings(os.path.join(test_dir, 'at least this file.txt')), \"TXT File parsed incorrectly\"\n",
    "assert \"A. Image classification\" in get_file_strings(os.path.join(test_dir, 'deep-features-scene (1).pdf')), \"PDF File parsed incorrectly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(query):\n",
    "    #TODO implement search procedure\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"segmentation\", \"algorithm\", \"printf\", \"predecessor\", \"Huffman\",\n",
    "           \"function\", \"constructor\", \"machine learning\", \"dataset\", \"Protasov\"]\n",
    "\n",
    "for query in queries:\n",
    "    r = find(query)\n",
    "#     print(\"Results for: \", query)\n",
    "#     print(\"\\t\", r)\n",
    "    assert len(r) > 0, \"Query should return at least 1 document\"\n",
    "    assert len(r) > 1, \"Query should return at least 2 documents\"\n",
    "    assert \"at least this file.txt\" in r, \"This file has all the queries. It should be in a result\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parse me if you can #\n",
    "\n",
    "Sometimes when crawling we have to parse websites that turn out to be SaaS - i.e., there is a special JS application which renders documents and which is downloaded first. Therefore, data that is to be rendered initially comes in a proprietary format. One of the examples is Google Drive. Last time we downladed and parsed some files from GDrive, however, we didn't parse GDrive-specific file formats, such as google sheets or google slides.\n",
    "\n",
    "Today we will learn to obtain and parse such data using Selenium - a special framework for testing web-applications.\n",
    "\n",
    "## 2.1. Getting started\n",
    "\n",
    "Let's try to load and parse the page the way we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "resp = requests.get(\"https://docs.google.com/presentation/d/1LuZvz3axBD8UuHLagdv0EbhsGEWJmpd7gN5KjwYCp9Y/edit?usp=sharing\")\n",
    "soup = BeautifulSoup(resp.text, 'lxml')\n",
    "print(soup.body.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the output is not what we expect. So, what can we do when a page is not being loaded right away, but is rather rendered by a script? Browser engines can help us get data. Let's try to load the same web-page, but do it in a different way: let's give some time to a browser to load the scripts and run them; and then will work with DOM (Document Object Model), but will get it from browser engine itself, not from BeautifulSoup.\n",
    "\n",
    "Where do we get browser engine from? Simply installing a browser will do the thing. How do we send commands to it from code and retrieve DOM? Service applications called drivers will interpret out commands and translate them into browser actions.\n",
    "\n",
    "\n",
    "For each browser engine suport you will need to:\n",
    "1. install browser itself;\n",
    "2. download 'driver' - binary executable, which passed commands from selenium to browser. E.g. [Gecko == Firefox](https://github.com/mozilla/geckodriver/releases), [ChromeDriver](http://chromedriver.storage.googleapis.com/index.html);\n",
    "3. unpack driver into a folder under PATH environment variable. Or specify exact binary location.\n",
    "\n",
    "### 2.1.1. Download driver\n",
    "\n",
    "And place it in any folder or under PATH env. variable.\n",
    "\n",
    "### 2.1.2. Install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Launch browser\n",
    "\n",
    "This will open browser window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "# or explicitly\n",
    "# browser = webdriver.Firefox(\n",
    "#     executable_path='C:/bin/geckodriver.exe', \n",
    "#     firefox_binary='C:/Program Files/Mozilla Firefox/firefox.exe'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4. Download the page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to page\n",
    "browser.get('http://tiny.cc/00dhkz')\n",
    "browser.implicitly_wait(5)  # wait 5 seconds\n",
    "\n",
    "# select all text parts from document\n",
    "elements = browser.find_elements_by_css_selector(\"g.sketchy-text-content-text\")\n",
    "# note that if number differs from launch to launch this means better extend wait time\n",
    "print(\"Elements found:\", len(elements))\n",
    "\n",
    "# oh no! It glues all the words!\n",
    "print(\"What if just a silly approach:\", elements[0].text)\n",
    "\n",
    "# GDrive stores all text blocks word-by-word\n",
    "subnodes = elements[0].find_elements_by_css_selector(\"text\")\n",
    "text = \" \".join(n.text for n in subnodes)\n",
    "print(\"What if a smart approach:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Too slow, wait for browser to open, browser to render\n",
    "\n",
    "## 2.2. Headless\n",
    "\n",
    "Browsers (at least [FF](https://developer.mozilla.org/en-US/docs/Mozilla/Firefox/Headless_mode), [Chrome](https://intoli.com/blog/running-selenium-with-headless-chrome/), IE) have headless mode - no window rendering and so on. Means it should work much faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.FirefoxOptions()\n",
    "\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size=1200x600')\n",
    "browser = webdriver.Firefox(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAME CODE\n",
    "\n",
    "# navigate to page\n",
    "browser.get('http://tiny.cc/00dhkz')\n",
    "browser.implicitly_wait(5)  # wait 5 seconds\n",
    "\n",
    "# select all text parts from document\n",
    "elements = browser.find_elements_by_css_selector(\"g.sketchy-text-content-text\")\n",
    "# note that if number differs from launch to launch this means better extend wait time\n",
    "print(\"Elements found:\", len(elements))\n",
    "\n",
    "# oh no! It adds NEW LINE. Behavior differs!!!!\n",
    "print(\"What if just a silly approach:\", elements[0].text)\n",
    "\n",
    "# GDrive stores all text blocks word-by-word\n",
    "subnodes = elements[0].find_elements_by_css_selector(\"text\")\n",
    "text = \" \".join(n.text for n in subnodes)\n",
    "print(\"What if a smart approach:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. NB \n",
    "Note, that browser behavior differs for the same code!\n",
    "\n",
    "## 2.3. Task \n",
    "Our lectures usually have lot's of links. Here are the links to original (spring 2020) versions of the documents.\n",
    "\n",
    "[4. Vector space](https://docs.google.com/presentation/d/1UxjGZPPrPTM_3lCa_gWTk8yZI_qNmTKwtMxr8JZQCIc/edit?usp=sharing)\n",
    "\n",
    "[6. search trees](https://docs.google.com/presentation/d/1LuZvz3axBD8UuHLagdv0EbhsGEWJmpd7gN5KjwYCp9Y/edit?usp=sharing)\n",
    "\n",
    "[7-8. Web basics](https://docs.google.com/presentation/d/1bgsCgpjMcQmrFpblRI6oH9SnG4bjyo5SzSSdKxxHNlg/edit?usp=sharing)\n",
    "\n",
    "Please complete the following tasks:\n",
    "\n",
    "### 2.3.1. Search for slides with numbers\n",
    "I want to type a word, and it should say which slides of which lecture has this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextAndImgsFromSlides(url):    \n",
    "    slides_text = dict() # dictionary slide_num : slide_text\n",
    "    img_list = [] # list of image urls \n",
    "    #TODO: parse google slides and save all text and image urls in slides_text and img_list\n",
    "    # you should get the contents from ALL slides - however, you will see that at one moment \n",
    "    # of time only single slide + few slide previews on the left are visible. To be able to    \n",
    "    # reach all slides you will need to scroll to and click these previews. While slide contents \n",
    "    # can be obtained from previews themselves, speaker notes (which you also have to extract)\n",
    "    # can be viewed only if a particular slide is open.\n",
    "    # to scroll the element of interest into view, use can this: \n",
    "    # browser.execute_script(\"arguments[0].scrollIntoView();\", el)\n",
    "    # to click the element, use can use ActionChains library   \n",
    "    \n",
    "    \n",
    "    return slides_text, img_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing three presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\"https://docs.google.com/presentation/d/1UxjGZPPrPTM_3lCa_gWTk8yZI_qNmTKwtMxr8JZQCIc/edit?usp=sharing\", \n",
    "         \"https://docs.google.com/presentation/d/1LuZvz3axBD8UuHLagdv0EbhsGEWJmpd7gN5KjwYCp9Y/edit?usp=sharing\",\n",
    "         \"https://docs.google.com/presentation/d/1bgsCgpjMcQmrFpblRI6oH9SnG4bjyo5SzSSdKxxHNlg/edit?usp=sharing\"]\n",
    "\n",
    "all_imgs = []\n",
    "all_texts = dict()\n",
    "\n",
    "for i, link in enumerate(links):\n",
    "    texts, imgs = getTextAndImgsFromSlides(link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, imgs = getTextAndImgsFromSlides('http://tiny.cc/00dhkz')\n",
    "\n",
    "assert len(texts) == 35 # equal to the total number of slides in the presentation \n",
    "print(len(texts))\n",
    "\n",
    "assert len(imgs) > 26 # can be more than that due to visitor icons\n",
    "print(len(imgs))\n",
    "\n",
    "assert any(\"Navigable\" in value for value in texts.values()) # word is on a slide\n",
    "assert any(\"MINUS\" in value for value in texts.values()) # word is in speaker notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"architecture\", \"algorithm\", \"function\", \"dataset\", \n",
    "           \"Protasov\", \"cosine\", \"модель\", \"например\"]\n",
    "\n",
    "for query in queries:\n",
    "    r = find(query)\n",
    "    print(\"Results for: \", query)\n",
    "    print(\"\\t\", r)\n",
    "    assert len(r) > 0, \"Query should return at least 1 document\"\n",
    "    assert len(r) > 1, \"Query should return at least 2 documents\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
